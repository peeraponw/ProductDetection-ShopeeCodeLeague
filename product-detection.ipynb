{"cells":[{"cell_type":"code","metadata":{"tags":[],"cell_id":"3cd5c461-8e74-4e14-ba41-2c64feed9f2b"},"source":"# Check S3 connection directory\r\n!ls /datasets/shopee-week2","execution_count":null,"outputs":[{"name":"stdout","text":"shopee-product-detection-dataset.zip\r\n","output_type":"stream"}]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"98eb5475-1813-4967-a7b2-152d8abba65e"},"source":"idx = 22\r\npremodel_name = 'effnetb7'\r\noptimizer = 'adam'\r\nis_class_weight = True\r\ndropout = 0.2\r\ndense = 256\r\nepochs = 10\r\nimage_size = 299\r\nbatch_size = 32","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"326407eb-30e5-417d-b5e2-5649cc457f86"},"source":"import numpy as np\r\nimport pandas as pd\r\nimport zipfile\r\nimport os\r\nimport matplotlib.pyplot as plt\r\nimport glob\r\nfrom time import time\r\n%matplotlib inline\r\n\r\nimport tensorflow as tf\r\nfrom PIL import Image\r\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\r\nfrom efficientnet.tfkeras import EfficientNetB4, EfficientNetB7\r\nfrom sklearn.utils.class_weight import compute_class_weight\r\n\r\n\r\nphysical_devices = tf.config.experimental.list_physical_devices('GPU')\r\ntf.config.experimental.set_memory_growth(physical_devices[0], True)\r\n\r\nprint(\"Tensorflow version:\", tf.__version__)\r\ngpus = tf.config.list_physical_devices('GPU')\r\nprint(\"Is using GPU?\", gpus)\r\n\r\ntf.config.experimental.set_memory_growth(gpus[0], True)","execution_count":null,"outputs":[{"name":"stdout","text":"Tensorflow version: 2.2.0\nIs using GPU? [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Import and organize files","metadata":{"tags":[],"cell_id":"0754192d-8883-451e-a52b-7ffec2f92e20"}},{"cell_type":"code","metadata":{"tags":[],"cell_id":"430bffe0-13a3-4ec7-8468-3ae474c823da"},"source":"# Check if the zip file has been extracted. Otherwise, extract from S3 connection\r\ncopyflag=False\r\nif not (os.path.isdir(\"train/train\") and os.path.isdir(\"test/test\")):\r\n    with zipfile.ZipFile(\"/datasets/shopee-week2/shopee-product-detection-dataset.zip\", \"r\") as zfile:\r\n        zfile.extractall(\".\")\r\n    copyflag=True\r\n# #\r\n# get path return generator of files\r\ndef files(path):\r\n    '''\r\n    Return generator of files in a given path\r\n\r\n    argument: path\r\n    return: file\r\n    '''\r\n    \r\n    for f in os.listdir(path):\r\n        if os.path.isfile(os.path.join(path, f)):\r\n            yield f\r\n# if there are still subfolders, move them to the train folder\r\nif copyflag: # do moving only if the files are freshly extracted\r\n    for dirpath, dirnames, filenames in os.walk(\"train/train\", topdown=False):\r\n        # walh through the training folder\r\n        if dirnames: # if folder exists\r\n            for d in dirnames:\r\n                for f in files(d): # move all files inside folder to training folder\r\n                    os.replace(os.path.join(d, f), os.path.join(\"train/train\", f))\r\n\r\n# remove empty folders after moving\r\ndef drop_empty_folders(path):\r\n    '''\r\n    remove empty subfolders in a given path\r\n\r\n    argument: path\r\n    return: none\r\n    '''\r\n    for dirpath, dirnames, filenames in os.walk(path, topdown=False):\r\n        if not dirnames and not filenames:\r\n            os.rmdir(dirpath)\r\ndrop_empty_folders(\"train/train\")\r\n\r\n\r\n# # check number of extracted files\r\ntrain_files = os.listdir(\"train/train\")\r\ntest_files = os.listdir(\"test/test\")\r\n\r\ndf_train = pd.read_csv(\"train.csv\", dtype=str)\r\ndf_test = pd.read_csv(\"test.csv\", dtype=str)\r\n\r\n# check if number of image files is equal to number of index in csv\r\nprint(f\"Number of training images: {len(train_files)}\")\r\nprint(f\"Number of training indices: {df_train.shape[0]}\")\r\nprint(f\"Number of testing images: {len(test_files)}\")\r\nprint(f\"Number of testing indices: {df_test.shape[0]}\")\r\n\r\n","execution_count":null,"outputs":[{"name":"stdout","text":"Number of training images: 105398\nNumber of training indices: 105392\nNumber of testing images: 12192\nNumber of testing indices: 12186\n","output_type":"stream"}]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"21f2840c-da76-4269-b411-568264f8e554"},"source":"def remove_tmp_files(path, img_files):\r\n    '''\r\n    remove files ending with .tmp in a given path\r\n\r\n    argument: path, list of filenames\r\n    return: list of filenames\r\n    '''\r\n    print(f\"Inspecting path: {path}\")\r\n    for f in glob.glob(os.path.join(path, '*.tmp')):\r\n        f = f.rsplit('/')[-1]\r\n        try:\r\n            img_files.remove(f)\r\n            print(f\"Removing file: {f}\")\r\n        except:\r\n            print(f\"Trying to remove non-existing file: {f}\")\r\n    return img_files\r\ntrain_files = remove_tmp_files('train/train', train_files)\r\ntest_files = remove_tmp_files('test/test', test_files)\r\n\r\n# check again if number of image files is equal to number of index in csv\r\nprint(f\"Number of training images: {len(train_files)}\")\r\nprint(f\"Number of training indices: {df_train.shape[0]}\")\r\nprint(f\"Number of testing images: {len(test_files)}\")\r\nprint(f\"Number of testing indices: {df_test.shape[0]}\")","execution_count":null,"outputs":[{"name":"stdout","text":"Inspecting path: train/train\nRemoving file: b4c1a220fd3a43961017717d953fb4e5.jpgk4d4lnxk.tmp\nRemoving file: 6b6e7a2db5acf395ee36077808f32e3d.jpgt13z3ib7.tmp\nRemoving file: 8235bf4e577b890f5a5ecfda00951f84.jpgt3reyw1v.tmp\nRemoving file: a6f9b9e65c3576a64452961a21678395.jpg95ta80mt.tmp\nRemoving file: 4af102e634973b11e5ab90cdee121a6d.jpgt0581za2.tmp\nRemoving file: 4e658733865eebe2461c322a54379e7f.jpg8afrrohw.tmp\nInspecting path: test/test\nNumber of training images: 105392\nNumber of training indices: 105392\nNumber of testing images: 12192\nNumber of testing indices: 12186\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Get random batch","metadata":{"tags":[],"cell_id":"71013d07-9fa6-4d89-b385-412075519f31"}},{"cell_type":"code","metadata":{"tags":[],"cell_id":"cbcaa1a9-0a9a-4c86-a8ea-73e09659e30e"},"source":"image_dir = 'train/train/'\r\nimage_size = image_size # [96, 128, 160, 192, 224]\r\n\r\ndef get_random_batch(df, batch_size=4):\r\n    \r\n    indices = np.random.choice(range(df.shape[0]), batch_size, replace=False)\r\n    x = np.zeros((batch_size, image_size, image_size, 3))\r\n    y = np.zeros((batch_size, 1))\r\n    images = []\r\n\r\n    for i, index in enumerate(indices):\r\n        image = tf.keras.preprocessing.image.load_img(os.path.join(image_dir, df.loc[index]['filename']), \r\n                                                        target_size=(image_size,image_size))\r\n        images.append(image)\r\n        arr = tf.keras.preprocessing.image.img_to_array(image)\r\n        arr = tf.keras.applications.mobilenet_v2.preprocess_input(arr)\r\n        arr = np.expand_dims(arr, axis=0)\r\n        x[i] = arr\r\n        y[i] = int(df.loc[index]['category'])\r\n    return x, y, images\r\n\r\ndef display_examples(x, y, p, images, df):\r\n\r\n    print('Displaying first 8 examples..')\r\n\r\n    if len(images) < 8:\r\n        print('Need at least 8 examples')\r\n        return None\r\n\r\n    plt.figure(figsize=(12, 8))\r\n    for i in range(8):\r\n        plt.subplot(2, 4, i + 1)\r\n        plt.imshow(images[i])\r\n        plt.xticks([])\r\n        plt.yticks([])\r\n        col = 'green' if y[i][0]==p[i][0] else 'red'\r\n        plt.xlabel(p[i][0], color=col)\r\n    return plt","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"aedb6c3a-d460-4e3a-9599-fb8011a2df0b"},"source":"x, y, images = get_random_batch(df_train, batch_size=8)\r\ndisplay_examples(x, y, y, images, df_train).show()","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preprocess data\r\n","metadata":{"tags":[],"cell_id":"e69ea08f-9275-4e8c-90f6-15231ae4f81c"}},{"cell_type":"markdown","source":"## Get random eraser","metadata":{"tags":[],"cell_id":"8c24355c-9921-4eb2-901d-40a6c2fbf0a8"}},{"cell_type":"code","metadata":{"tags":[],"cell_id":"dcd336ca-f78c-4fd8-a901-bd7abc07ad70"},"source":"def get_random_eraser(p=0.5, s_l=0.02, s_h=0.4, r_1=0.3, r_2=1/0.3, v_l=0, v_h=255, pixel_level=False):\r\n    def eraser(input_img):\r\n        img_h, img_w, img_c = input_img.shape\r\n        p_1 = np.random.rand()\r\n\r\n        if p_1 > p:\r\n            return input_img\r\n\r\n        while True:\r\n            s = np.random.uniform(s_l, s_h) * img_h * img_w\r\n            r = np.random.uniform(r_1, r_2)\r\n            w = int(np.sqrt(s / r))\r\n            h = int(np.sqrt(s * r))\r\n            left = np.random.randint(0, img_w)\r\n            top = np.random.randint(0, img_h)\r\n\r\n            if left + w <= img_w and top + h <= img_h:\r\n                break\r\n\r\n        if pixel_level:\r\n            c = np.random.uniform(v_l, v_h, (h, w, img_c))\r\n        else:\r\n            c = np.random.uniform(v_l, v_h)\r\n\r\n        input_img[top:top + h, left:left + w, :] = c\r\n\r\n        return input_img\r\n\r\n    return eraser","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"6ff66f72-b702-4fa1-969f-cc89a3af1a93"},"source":"disp_eraser = get_random_eraser(v_l = 0., v_h = 255., pixel_level=True, p=1)\r\nx, y, images = get_random_batch(df_train, batch_size=8)\r\ndisplay_examples(x, y, y, [disp_eraser(np.array(im)) for im in images], df_train).show()\r\n","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Splitting train and val set","metadata":{"tags":[],"cell_id":"a695fcbf-f83e-4490-b4eb-fdd40a6fa67c"}},{"cell_type":"code","metadata":{"tags":[],"cell_id":"3b8dc7c8-82ca-4e37-81b6-01aa8cf98b92"},"source":"def splitting_data(df, train_ratio=0.9):\r\n    indices = np.random.choice(df.shape[0], int(train_ratio*df.shape[0]), replace=False)\r\n    remaining = set(df.index) - set(indices)\r\n    df_model = df.loc[indices].reset_index()\r\n    df_val = df.loc[remaining].reset_index()\r\n    return df_model, df_val\r\ndf_model, df_val = splitting_data(df_train, train_ratio=0.90)\r\nprint(\"Original shape: \", df_train.shape[0])\r\nprint(\"df_model shape: \", df_model.shape[0])\r\nprint(\"df_val shape: \", df_val.shape[0])","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"66c3d31d-689b-4e0b-8a96-f4c40aa6fd15"},"source":"# compare density of splitting categories\r\nfig = plt.figure(figsize=(12,4))\r\nplt.subplot(1,2,1)\r\nplt.hist(df_model['category'], density=True, bins=42)\r\nplt.title(\"y_train\")\r\nplt.subplot(1,2,2)\r\nplt.hist(df_val['category'], density=True, bins=42)\r\nplt.title(\"y_val\")\r\nplt.show()","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"32d9c010-1fec-4eac-9909-84d9da7136c9"},"source":"cat_cols = df_model['category'].unique()\r\nif is_class_weight == True:\r\n    class_weight = compute_class_weight('balanced',\r\n                                        np.unique(df_model['category']),\r\n                                        df_model['category'])\r\n    class_weight = dict(enumerate(class_weight))\r\nelse:\r\n    class_weight = {c: 1 for c in range(cat_cols.shape[0])}\r\nclass_weight","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create model","metadata":{"tags":[],"cell_id":"99cf034a-abd0-4c39-a7ad-2172c70187f5"}},{"cell_type":"code","metadata":{"tags":[],"cell_id":"afee98a8-aa3b-4bcd-982b-ee9fb7ba63ea"},"source":"if premodel_name == 'mnet':\r\n    premodel = tf.keras.applications.mobilenet_v2.MobileNetV2(\r\n        include_top=False, input_shape=(image_size, image_size, 3),\r\n        pooling='avg', weights='imagenet')\r\n\r\nelif premodel_name == 'effnetb4':\r\n    premodel = EfficientNetB4(\r\n        include_top=False, input_shape=(image_size, image_size, 3),\r\n        pooling='avg', weights='imagenet'\r\n    )\r\n\r\nelif premodel_name == 'effnetb7':\r\n    premodel = EfficientNetB7(\r\n        include_top=False, input_shape=(image_size, image_size, 3),\r\n        pooling='avg', weights='imagenet'\r\n    )\r\npremodel.summary()","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"7eced282-9ec4-49a6-bbe0-aa7d0bd2a722"},"source":"def create_model():\r\n    model = tf.keras.models.Sequential([\r\n        premodel,\r\n        tf.keras.layers.Dense(dense, activation='relu'),\r\n        tf.keras.layers.Dropout(dropout),\r\n        tf.keras.layers.Dense(dense, activation='relu'),\r\n        tf.keras.layers.Dropout(dropout),\r\n        tf.keras.layers.Dense(42, activation='softmax')\r\n    ])\r\n\r\n    model.layers[0].trainable = False\r\n    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['acc'])\r\n    return model\r\n\r\nmodel = create_model()\r\nmodel.summary()","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model training","metadata":{"tags":[],"cell_id":"bf923bb5-d0b4-409f-98fa-f40569cfc751"}},{"cell_type":"code","metadata":{"tags":[],"cell_id":"c24e4129-c902-4706-8820-e948796680c2"},"source":"\r\nbatch_size = batch_size\r\nsteps_per_epoch = int(df_model.shape[0]/batch_size)\r\nvalidation_steps = int(df_val.shape[0]/batch_size)\r\n\r\nprint('Steps per epoch:', steps_per_epoch)\r\nprint('Validation steps:', validation_steps)\r\n\r\n\r\ndef preprocess_input(img):\r\n    \r\n    img = tf.keras.applications.mobilenet_v2.preprocess_input(img)\r\n    eraser = get_random_eraser(v_l=-1., v_h=1., pixel_level=True, p=0.5)\r\n    img = eraser(img)\r\n    return img\r\n\r\ntrain_datagen = ImageDataGenerator(\r\n    rotation_range=40,\r\n    width_shift_range=0.2,\r\n    height_shift_range=0.2,\r\n    shear_range=0.2,\r\n    zoom_range=0.2,\r\n    horizontal_flip=True,\r\n    fill_mode='nearest',\r\n    preprocessing_function=preprocess_input\r\n)\r\n\r\ntrain_generator = train_datagen.flow_from_dataframe(\r\n    df_model,\r\n    directory=image_dir,\r\n    x_col='filename',\r\n    y_col='category',\r\n    class_mode='categorical',\r\n    target_size=(image_size, image_size),\r\n    batch_size=batch_size\r\n)\r\n\r\nvalidation_datagen = ImageDataGenerator(\r\n    preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input\r\n    )\r\n\r\nvalidation_generator = validation_datagen.flow_from_dataframe(\r\n    df_val,\r\n    directory=image_dir,\r\n    x_col='filename',\r\n    y_col='category',\r\n    class_mode='categorical',\r\n    target_size=(image_size, image_size),\r\n    batch_size=batch_size\r\n)","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"373b5c86-398e-4b90-ae1e-a3ad5ea81ca4"},"source":"\r\nstart_time = time()\r\nh = model.fit(\r\n    train_generator,\r\n    validation_data = validation_generator,\r\n    steps_per_epoch=steps_per_epoch,\r\n    validation_steps=validation_steps,\r\n    verbose=1,\r\n    epochs=epochs,\r\n    class_weight=class_weight, \r\n    callbacks=[\r\n        tf.keras.callbacks.EarlyStopping(monitor='val_acc', patience=2),\r\n        tf.keras.callbacks.ModelCheckpoint('models/model_{val_acc:.3f}.h5', save_best_only=True,\r\n                                          save_weights_only=False, monitor='val_acc')\r\n    ]\r\n\r\n    )\r\n\r\n\r\nprint(\"Wall time: \", time()-start_time)\r\n","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"b476ecf2-c1bf-4115-b2d9-df1a23ddcc16"},"source":"losses = h.history['loss']\r\naccs = h.history['acc']\r\nval_losses = h.history['val_loss']\r\nval_accs = h.history['val_acc']\r\nepochs = len(losses)\r\n\r\nplt.figure(figsize=(12, 4))\r\nfor i, metrics in enumerate(zip([losses, accs], [val_losses, val_accs], ['Loss', 'Accuracy'])):\r\n    plt.subplot(1, 2, i + 1)\r\n    plt.plot(range(epochs), metrics[0], label='Training {}'.format(metrics[2]))\r\n    plt.plot(range(epochs), metrics[1], label='Validation {}'.format(metrics[2]))\r\n    plt.legend()\r\nplt.show()\r\n\r\nprint(\"Loss: {:.4f}\".format(losses[-1]))\r\nprint(\"Acc: {:.4f}\".format(accs[-1]))\r\nprint(\"Val Loss: {:.4f}\".format(val_losses[-1]))\r\nprint(\"Val Accs: {:.4f}\".format(val_accs[-1]))","execution_count":0,"outputs":[]},{"cell_type":"markdown","source":"# Visualize validations","metadata":{"tags":[],"cell_id":"37e5364e-3d48-4aa7-9d8a-5b11e7634bd8"}},{"cell_type":"code","metadata":{"tags":[],"cell_id":"48f253cf-31fd-46ee-8a84-cb172a0b6cf0"},"source":"x, y, images = get_random_batch(df_val, batch_size=8)\r\npreds = model.predict(x).argmax(axis=1).reshape(-1,1)\r\ndisplay_examples(x, y, preds, images, df_val).show()","execution_count":0,"outputs":[]},{"cell_type":"markdown","source":"# Make prediction   ","metadata":{"tags":[],"cell_id":"62021335-9b08-41de-b607-8a421d9f220e"}},{"cell_type":"code","metadata":{"tags":[],"cell_id":"e6334856-414a-43d5-911e-eea35c03abb7"},"source":"# model.load_weights('models/model_0.686.h5')","execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"01f02b4e-6571-431c-a6a6-5ed36fe6a938"},"source":"def create_prediction(df, batch_size=8, image_dir='test/test'):\r\n    \r\n    y = np.zeros((df.shape[0], 1))\r\n    steps = int(df.shape[0]/batch_size)\r\n    for i in range(0, steps+1):\r\n        df_sub = df.loc[i*batch_size: (i+1)*batch_size].reset_index()\r\n        if i == steps:\r\n            batch_size = df.shape[0] % batch_size\r\n        x = np.zeros((batch_size, image_size, image_size, 3))\r\n        for j in range(0, batch_size):\r\n            image = tf.keras.preprocessing.image.load_img(os.path.join(image_dir, df_sub.loc[j,'filename']), \r\n                                                            target_size=(image_size,image_size))\r\n            arr = tf.keras.preprocessing.image.img_to_array(image)\r\n            arr = tf.keras.applications.mobilenet_v2.preprocess_input(arr)\r\n            arr = np.expand_dims(arr, axis=0)\r\n            x[j] = arr\r\n        if i == steps:\r\n            y[-batch_size:] = model.predict(x).argmax(axis=1).reshape(-1,1)\r\n        else:\r\n            y[i*batch_size: (i+1)*batch_size] = model.predict(x).argmax(axis=1).reshape(-1,1)\r\n    df['category'] = y\r\n    df['category'] = df['category'].apply(lambda v: str(int(v)).zfill(2))\r\n    return df\r\ndf_submit = create_prediction(df_test, batch_size=64)\r\ndf_submit","execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"c396c418-0277-4439-bee2-c747e4f4710f"},"source":"plt.hist(df_submit['category'], bins=42, density=True)\r\nplt.show()","execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"7b35bea3-ebc7-4f5c-8388-83654fd09322"},"source":"df_submit.to_csv('submit.csv', index=False)","execution_count":0,"outputs":[]}],"nbformat":4,"nbformat_minor":2,"metadata":{"orig_nbformat":2,"deepnote_notebook_id":"1ec1bf80-956f-40c2-9a08-e2cbf55c77a6","deepnote_execution_queue":[]}}